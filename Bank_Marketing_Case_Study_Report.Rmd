---
title: "Bank Marketing Case Study 1"
author: "Dominica Peri"
date: "2025-09-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

1. Executive Summary (Last)

2. The Problem
    1. Introduction/Background
    2. Purpose of study/importance of study/statement of problem
    3. Questions to be answered/conceptual statement of hypotheses
    4. Outline of remainder of report (brief)
    
3. Review of Related Literature
    1. Acquaint reader with existing methodologies used in this area
    
4. Methodology
    1. Identification, classification and operationalization of variables.
    2. Statements of hypotheses being tested and/or models being developed.
    3. Sampling techniques, if full data is not being used.
    4. Data collection process, including data sources, data size, etc. Primary/secondary?
    5. Modeling analysis/techniques used
    6. Methodological assumptions and limitations.
    
5. Data
    1. Data cleaning
    2. Data preprocessing
    3. Data limitations
    
6. Findings (Results)
    1. Results presented in tables or charts when appropriate
    2. Results reported with respect to hypotheses/models.
    3. Factual information kept separate from interpretation, inference and evaluation.
    
7. Conclusions and Recommendations
    1. Discuss alternative methodologies

#____________________________________________________________________________

Load Libraries

```{r Libraries}
library(MASS) 
library(ggplot2)
library(tidyverse)
library(corrplot)
library(car)
library(GGally)
library(ROCR)
library(data.table)
library(Hmisc)
library(tibble)
library(knitr)
library(here)
library(ROCR)
```

Import Data

```{r}
data_path <- "https://raw.githubusercontent.com/kccasey1985/Case-Study-Bank-Marketting-/main/bank-additional-full.csv"

df <- fread(data_path, sep = ";") |> as_tibble()
glimpse(df)
```
```{r}
opts_knit$set(root.dir = here())

# load the dataset
df <- fread(here("bank-additional-full.csv"), sep = ";") |> as_tibble()
glimpse(df)
```


```{r }

head(df)

```


```{r }

str(df)

```

```{r}

summary(df)

```

```{r }

df2 <- df |> 
  mutate(job = factor(job),
         marital  = factor(marital),
         education  = factor(education),
         default  = factor(default),
         loan  = factor(loan),
         contact  = factor(contact),
         month   = factor(month),
         day_of_week  = factor(day_of_week),
         poutcome    = factor(poutcome),
         y   = factor(y),
         housing  = factor(housing))



```

```{r }

str(df2)

```

```{r }

summary(df2)

```
```{r }

anyNA(df2)

```


```{r }

df2 <- df2 |> mutate(age= cut(age, breaks = c(20, 30, 40, 50, 60, 70, 100),
                         labels = c("21-30", "31-40", "41-50", "51-60", "61-70", "71+"),
                         right = F))|>
            select(-duration)

```

```{r }

summary(df2)

```


```{r }

df2_num <- dplyr::select_if(df2, is.numeric)
matrix = cor(df2_num)
corrplot(matrix, method = c("number")) 

```







```{r }

corrplot::corrplot(matrix, method = "circle")


```





```{r }

#lm_model <- lm(y ~ ., data = df2)a2  

```
```{r}

# Make sure y is a factor with two levels
df2$y <- factor(df2$y, levels = c("no", "yes"))

# Logistic regression
logit_model <- glm(y ~ ., data = df2, family = binomial)

summary(logit_model)

```
```{r}
#alias(lm_model)

```


```{r }

#vif_values <- car::vif(logistic)

#print(vif_values)


```

```{r}

#remove factors with greater than 0.875 correlation with other factors

df3 <- subset(df2, select = -c(emp.var.rate,cons.price.idx,euribor3m,nr.employed))


df3

```

```{r}

df3_num <- dplyr::select_if(df3, is.numeric)
matrix2 = cor(df3_num)
corrplot(matrix2, method = c("number")) 


```



```{r}

# Logistic regression with df3

lm_model_2 <- lm(y ~ . , data = df3)

```


```{r}

logit_model2 <- glm(y ~ ., data = df3, family = binomial)

summary(logit_model2)

```

```{r}

# Make sure y is a factor with two levels
df3$y <- factor(df3$y, levels = c("no", "yes"))

# Logistic regression
logit_model <- glm(y ~ ., data = df3, family = binomial)

summary(logit_model)

```

```{r}
#LDA

# Ensure clean data for both models
df_clean <- df3[complete.cases(df3), ]

# Train logistic model (already done earlier, so skip if done)
# logit_model <- glm(y ~ ., data = df_clean, family = binomial)

# Train LDA model
library(MASS)
lda_model <- lda(y ~ ., data = df_clean)

summary(lda_model)

```

```{r}

# Predict probabilities
logit_probs <- predict(logit_model, newdata = df_clean, type = "response")
logit_pred <- prediction(logit_probs, df_clean$y)
logit_perf <- performance(logit_pred, "tpr", "fpr")

# Plot ROC
plot(logit_perf, col = "blue", lwd = 2,
     main = "ROC Curve: Logistic Regression")
abline(a = 0, b = 1, lty = 2, col = "gray")

# AUC
logit_auc <- performance(logit_pred, "auc")@y.values[[1]]
print(paste("Logistic Regression AUC:", round(logit_auc, 4)))
```

```{r}
# Predict probabilities from LDA
lda_pred <- predict(lda_model, newdata = df_clean)
lda_probs <- lda_pred$posterior[, 2]

# ROC and AUC for LDA
lda_roc <- prediction(lda_probs, df_clean$y)
lda_perf <- performance(lda_roc, "tpr", "fpr")

# Plot ROC
plot(lda_perf, col = "red", lwd = 2,
     main = "ROC Curve: Linear Discriminant Analysis")
abline(a = 0, b = 1, lty = 2, col = "gray")

# AUC
lda_auc <- performance(lda_roc, "auc")@y.values[[1]]
print(paste("LDA AUC:", round(lda_auc, 4)))

```
```{r}
# Create a data frame with model performance
model_summary <- data.frame(
  Model = c("Logistic Regression", "LDA"),
  AUC = c(round(logit_auc, 4), round(lda_auc, 4))
)

# Display the table nicely
knitr::kable(model_summary, caption = "Model Performance Summary (AUC)")

```
```{r}
# Logistic predicted classes
logit_pred_class <- ifelse(predict(logit_model, newdata = df_clean, type = "response") > 0.5, "yes", "no")

# LDA predicted classes
lda_pred_class <- predict(lda_model, newdata = df_clean)$class

```

```{r}
# Load required package
library(caret)

# Convert actual target
actual <- df_clean$y

# Confusion matrices
logit_cm <- confusionMatrix(factor(logit_pred_class, levels = c("no", "yes")), actual, positive = "yes")
lda_cm   <- confusionMatrix(factor(lda_pred_class, levels = c("no", "yes")), actual, positive = "yes")
print(logit_cm)
```
```{r}
# Get metrics from confusion matrix
logit_metrics <- logit_cm$byClass
lda_metrics   <- lda_cm$byClass

# Combine into table
model_metrics <- data.frame(
  Model       = c("Logistic Regression", "LDA"),
  Accuracy    = c(logit_cm$overall["Accuracy"], lda_cm$overall["Accuracy"]),
  Sensitivity = c(logit_metrics["Sensitivity"], lda_metrics["Sensitivity"]),
  Specificity = c(logit_metrics["Specificity"], lda_metrics["Specificity"]),
  AUC         = c(round(logit_auc, 4), round(lda_auc, 4))
)
# Display the table nicely
knitr::kable(model_metrics, caption = "Model Performance Metrics")
```

```{r}
```{r}
# Correlation 
df2_num <- dplyr::select_if(df2, is.numeric)
matrix = cor(df2_num)
corrplot(matrix, method = c("number")) 

# 4. Train/Test Split

# Balanced dataset
df2_yes = dplyr::filter(df2, Campaign_Response == 1)
df2_no = dplyr::filter(df2, Campaign_Response == 0)
df2_random = sample_n(df2_no, dim(df2_yes)[1])
# This is from when we saw the unbalance in the histogram earlier
df2_balance = rbind(df2_yes, df2_no_random)

# Set seed
set.seed(123)

# Unbalanced
train_index <- createDataPartition(df2$Campaign_Response, p = 0.7, list = F) 
train <- df[train_index,]
test <- df[-train_index,]

# Balanced
train_index_balance <- createDataPartition(df2$Campaign_Response, p = 0.7, list = F) 
train_balance <- df[train_index_balance,]
test_balance <- df[-train_index_balance,]

# 5. Logistic Regression

formula_lr <- Campaign_Response ~ Age_Group + Log_Income + Account_Balance + Credit_Score + Transactions_Per_Month + Loan_Repayment_Status + Digital_Banking_Usage + Gender + Marital_Status
lr_model <- glm(formula_lr, data = train, family = binomial)
lt_model_balance <- glm(formula_lr, data = train_balance, family = binomial) 

summary(lr_model)
summary(lr_model_balance)

vif(lr_model)
vif(lr_model_balance)

# Unbalanced predictions
test$prob_lr <- predict(lr_model, newdata = test, type = "response")
test$pred_lr <- ifelse(test$prob_lr > 0.5, "1", "0") |>
  factor(levels = c("0", "1"))

# Balanced predictions
test_balance$prob_lr <- predict(lr_model_balance, newdata = test_balance, type = "response")  
test_balance$pred_lr <- ifelse(test_balance$prob_lr > 0.5, "1", "0") |>
  factor(levels = c("0", "1"))

# AUC & Confusion Matrix
# Unbalanced
roc_lr <- roc(as.numeric(as.character(test$Campaign_Response, test$prob_lr)))
auc_lr <- roc_lr$auc
print(paste("Logistic Regression AUC: ", auc_lr))
print(ConfusionMatrix(test$pred_lr, test$Campaign_Response, positive = "1"))

# Balanced
roc_lr_balance <- roc(as.numeric(as.character(test$Campaign_Response, test$prob_lr)))
auc_lr_balance <- roc_lr_balance$auc
print(paste("Logistic Regression AUC: ", auc_lr_balance))
print(ConfusionMatrix(test_balance$pred_lr, test_balance$Campaign_Response, positive = "1"))

# 6. Decision Tree

formula_ml <- Campaign_Response ~ Age_Group + Log_Income + Account_Balance + Credit_Score + Transactions_Per_Month + Loan_Repayment_Status + Digital_Banking_Usage + Gender + Marital_Status
tree_model <- glm(formula_lr, data = train, family = "class")
tree_model_balance <- glm(formula_lr, data = train_balance, family = "class") 

rpart.plot(tree_model, main = "Decision Tree")
rpart.plot(tree_model_balance, main = "Decision Tree")

# Unbalanced predictions
test$prob_tree <- predict(tree_model, newdata = test)[, "1"]
test$pred_tree <- ifelse(test$prob_tree > 0.5, "1", "0") |>
  factor(levels = c("0", "1"))

# Balanced predictions
test_balance$prob_tree <- predict(tree_model_balance, newdata = test)[, "1"]
test_balance$pred_tree <- ifelse(test_balance$prob_tree > 0.5, "1", "0") |>
  factor(levels = c("0", "1"))

# AUC & Confusion Matrix
# Unbalanced
roc_tree <- roc(as.numeric(as.character(test$Campaign_Response, test$prob_tree)))
auc_tree <- roc_tree$auc
print(paste("Logistic Regression AUC: ", auc_tree))
print(ConfusionMatrix(test$pred_tree, test$Campaign_Response, positive = "1"))

# Balanced
roc_tree_balance <- roc(as.numeric(as.character(test$Campaign_Response, test_balance$prob_tree)))
auc_tree_balance <- roc_tree_balance$auc
print(paste("Logistic Regression AUC: ", auc_tree))
print(ConfusionMatrix(test_balance$pred_tree, test_balance$Campaign_Response, positive = "1"))

# 7. Random Forest

# Unbalanced
rf_model <- randomForest(x = model.matrix(formula_ml, data = train)[, -1],
                         y = train$Campaign_Response,
                         ntree = 150,
                         mtry = floor(sqrt(length(all.vars(formula_ml)))),
                         nodesize = 50,
                         importance = T)
varImpPlot(rf_model, main = "Random Forest")

# Balanced
rf_model_balance <- randomForest(x = model.matrix(formula_ml, data = train_balance)[, -1],
                                 y = train_balance$Campaign_Response,
                                 ntree = 150,
                                 mtry = floor(sqrt(length(all.vars(formula_ml)))),
                                 nodesize = 50,
                                 importance = T)
varImpPlot(rf_model_balance, main = "Random Forest")

# Unbalanced predictions
test_rf <- model.matrix(formula_ml, data = test)[, -1]
test$prob_rf <- predict(rf_model, newdata = test_rf, type = "prob")[, "1"]
test$pred_rf <- ifelse(test$prob_rf > 0.5, "1", "0") |>
  factor(levels = c("0", "1"))

# Balanced predictions
test_rf_balance <- model.matrix(formula_ml, data = test_balance)[, -1]
test$prob_rf_balance <- predict(rf_model_balance, newdata = test_rf_balance, type = "prob")[, "1"]
test$pred_rf_balance <- ifelse(test_balance$prob_rf_balance > 0.5, "1", "0") |>
  factor(levels = c("0", "1"))

# AUC & Confusion Matrix
# Unbalanced
roc_rf <- roc(as.numeric(as.character(test$Campaign_Response, test$prob_rf)))
auc_rf <- roc_rf$auc
print(paste("Logistic Regression AUC: ", auc_rf))
print(ConfusionMatrix(test$pred_rf, test$Campaign_Response, positive = "1"))

# Balanced
roc_rf_balance <- roc(as.numeric(as.character(test$Campaign_Response, test_balance$prob_rf_balance)))
auc_rf_balance <- roc_rf_balance$auc
print(paste("Logistic Regression AUC: ", auc_rf_balance))
print(ConfusionMatrix(test_balance$pred_rf_balance, test_balance$Campaign_Response, positive = "1"))

# 8. ROI Simulation

cost_per_contact <- 5
revenue_per_conversion <- 250

simulate_roi <- function(df_probs, prob_col = "prob"){
  n_total <- nrow(df_probs)
  
  # Mass marketing
  mass_contacts <- n_total
  mass_conversions <- sum(as.numeric(as.character(df_probs$Campaign_Response)))
  mass_cost <- mass_contacts * cost_per_contact
  mass_revenue <- mass_conversions * revenue_per_conversion
  mass_roi <- (mass_revenue - mass_cost) / mass_cost
  
  # Top 20%
  top20_n <- ceiling(0.20 * n_total)
  top20 <- df_probs %>% arrange(desc(.data[[prob_col]])) %>% slice(1:top20_n)
  top20_conversions <- sum(as.numeric(as.character(top20$Campaign_Response)))
  top20_cost <- top20_n * cost_per_contact
  top20_revenue <- top20_conversions * revenue_per_conversion
  top20_roi <- (top20_revenue - top20_cost) / top20_cost
  
  # Top 10%
  top10_n <- ceiling(0.10 * n_total)
  top10 <- df_probs %>% arrange(desc(.data[[prob_col]])) %>% slice(1:top10_n)
  top10_conversions <- sum(as.numeric(as.character(top10$Campaign_Response)))
  top10_cost <- top10_n * cost_per_contact
  top10_revenue <- top10_conversions * revenue_per_conversion
  top10_roi <- (top10_revenue - top10_cost) / top10_cost
  
  tibble(scenario = c("Mass (all)", "Target top 20%", "Target top 10%"),
         contacts = c(mass_contacts, top20_n, top10_n),
         conversions = c(mass_conversions, top20_conversions, top10_conversions),
         cost = c(mass_cost, top20_cost, top10_cost),
         revenue = c(mass_revenue, top20_revenue, top10_revenue),
         ROI = c(as.numeric(mass_roi), as.numeric(top20_roi), as.numeric(top10_roi)))
}

roi_lr <- simulate_roi(test |> rename(prob = prob_lr))
roi_lr_bal <- simulate_roi(test_bal |> rename(prob = prob_lr))

roi_tree <- simulate_roi(test |> rename(prob = prob_tree))
roi_tree_bal <- simulate_roi(test_bal |> rename(prob = prob_tree))

roi_rf <- simulate_roi(test |> rename(prob = prob_rf))
roi_rf_bal <- simulate_roi(test_bal |> rename(prob = prob_rf))


print(list(Logistic = roi_lr, 
           BalancedLogistic = roi_lr_bal,
           Tree = roi_tree, 
           BalancedTree = roi_tree_bal,
           RF = roi_rf, 
           BalancedRF = roi_rf_bal))
```
```

